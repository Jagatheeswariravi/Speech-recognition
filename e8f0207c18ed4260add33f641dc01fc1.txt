Brendan O'Connor on RTE. Radio One. Sponsored by Timberliving log cabins for your perfect workspace. Living space or hideaway timberliving. Ie brendan O'Connor on RTE Radio One. So now, Google launched their AI chatbot barred this week to March fanfare and Bard promptly made a $1 billion error on its first big oath. But look, all in all, it's been a big week in the advance of artificial intelligence into our lives. So we're joined now by Jenny Dharmondy of Silicon Republic. Good afternoon, Jenny. Good afternoon, Brendan. So listen, can you tell us first, Jenny, what happened this week? So Microsoft launched an AI version of their search engine, essentially. Yeah. So this has kind of been teased for a little while now. So it's called Chat GPT, which is a very advanced natural language processor, and Microsoft are essentially incorporating that into their search engine. And it's to give sort of more contextual answers, to understand the questions that humans are asking more and to kind of give better answers, basically. And it's kind of trying to challenge Google because obviously that's the biggest search engine. I tried to go on being their search engine and see how to do an AI search, but I didn't figure it out. But how will the internet searches be different with more AI involved in them? So it's basically going to give more human and contextual answers for what we're looking for. So in the way that I suppose at the moment you might search something on Google and it'll bring you up a bunch of different resources where you can go and kind of find the answer yourself and try to parse through things. The idea is that the search engine is going to kind of present you with the answer that you're actually looking for itself based on it's kind of doing the work for you, basically. Okay, so then I think, was it kind of in response to that, that Google rushed out their AI chat bot Barred and had a big high profile unveiling of it and what happened on its first outing? Yeah, so this is definitely the signs of a big massive AI arms race where everybody's kind of rushing to get out there first and it made a big show of bird and it gave it a prompt about new discoveries from the James Webb telescope. And one of the things it said was that the James Webb telescope was the first telescope to take pictures of planets outside of the Earth's solar system. And that was spotted by Reuters. That, that is absolutely incorrect. It was actually the European Southern Observatory's Very Large Telescope which took the first pictures. So it kind of accidentally showed its hand and that it can make mistakes and quite simple ones as well. That information is widely available. Okay, so is there kind of a credibility issue here with AI? Will AI just spoke whatever bull is out there and it basically doesn't even know what it's saying, that's certainly a danger. So we have to remember that artificial intelligence is a computer simulation of human intelligence. It's not actually intelligent in the way that humans are and it's not actually sentient. So it's learning from the reams and reams of data that's on the Internet and it can be made smart and the mistakes can definitely be corrected, I'm sure, over time. But it's very, very much in its infancy, so it's very new and it has a lot of kinks that it still needs to work out. So it's a very big rush and a big hullabaloo about it at the moment. But it's still very, very young and the technology still has a lot a long way to go, I suppose. So then, in terms of the name artificial intelligence, will it improve and learn as it goes along? Yeah, it can absolutely learn as it goes along. The only danger with that is the kind of it's only as clever as the data that it's being fed. So this is where some of the ethical issues come in, using AI, because if it's being fed reams and reams of data from the Internet, we already know the Internet is full of inaccuracies, misinformation and things like that. And there's been previous iterations of chat bots that have been put out there, things like Blenderbot from Meta and things like that that became conspiracy theorists quite quickly or quite racist or quite misogynistic, because it's learning from text that's on the Internet and we know the Internet is full of that stuff. So that's the kind of ethical line that needs to be worked out and that's the kind of kinks that need to be worked out. And there's a lot of things going on behind the scenes with the company OpenAI, which is behind chat GPT, where they are trying to fix those problems, like ensuring that there isn't bias, that there isn't hate speech and that there isn't mistakes. But it does have a long way to go. It can learn, but you have to be careful about the data that you're feeding us. And then did I see Elon Musk then, is worried, on the other hand, that it's all going to have a left wing bias? Yeah, well, Elon Musk is a problematic person in himself, I think. But I think there's worry on both sides. I think, as I said, those chat bots, there was one as well in 2016 called hey from Microsoft, and the one that I mentioned, Blenderbot, is from Meta. So there are two different platforms, two different companies, and they both kind of went down that there's what you would say, right wing stuff like anti, somatic hate speech, transphobic, things like that. So I wouldn't be too concerned about it being left so far because what we tend to see is hate speech that are from the other side. Okay, listen, is all this overhyped or is all this going to change our lives radically in the next couple of years. I think it will change the way we search things, the way we use Internet. I don't think that the advancements that have been made should be minimized. I think it'll generally make the technology that we use a lot better. But it does come with a massive caveat, which is that a lot of it is still very young. Like I said, those kinks need to be figured out. And there's also other ethical things that come with, even if it's working properly, because there's questions about plagiarism of content. There's concerns about job losses in the content area. So even if it advances and changes our lives irrevocably for the better from using technology, there's also other societal impacts that we need to consider, like those things. Now, there's also those jobs will come in different forms, like there'll be a need for more AI engineers, for example, and things like that. But that's not to be minimized because content creators won't suddenly turn around one day and become AI architects. So it's not that simple. Yeah. And I mean, I did see someone make the point that what this AI where it's learning from is reams and reams of work that was done by human beings and it's essentially taking their work and moving on with it. There were two recent examples, kind of in the popular culture of AI being used in a kind of a creative way. Can you tell me about this AI seinfeld Nothing Forever show that was going on? Yeah. So that was basically a live stream, kind of almost like a television show on a platform called Twitch. And it was called Nothing Forever to kind of parody the sort of Seinfeld is a show about nothing. And it kind of effectively was able to churn back out versions of things that would be natural tropes or storylines. And even Jerry Seinfeld's kind of stand up bits that are kind of bookending the show and things like that. And it did bring some of that nostalgic feel, I believe, to the fans of Seinfeld. But then it got taken down because it ended up kind of including a transphobic rant kind of in the middle of one of the standoff bits. Now, the reason that happened, I believe, is because there was an outage with the OpenAI platform, the DA Vinci model, and the program kind of automatically switched over to a backup system which was not nearly as well regulated. So that's how it kind of ended up happening. But that's the kind of stuff that come into the fray if it's not monitored or it's not checked and it's not got those barriers and regulations in place. And I see Nick Cave as well, has been giving out about, I believe, that AI generated nick Cave songs were starting to get really popular with people. Yes, someone sent him. I believe a lot of people have been sending him these kind of versions of basically, if you put in if you go into Chat GPT, you can ask it certain things like, write a song for me in the style of Nick Cave. And because Nick Cave's, obviously, songs and lyrics are so widely available on internet, it is able to quite easily learn from the style of Nick Cave and kind of churned back out. And I suppose a new song or a Frankenstein signed kind of song that might sound like something that Nick Cave might right now. He said it's trash, which I understand completely where he's coming from, because it's taking away a lot of the things that are inherently human, particularly when it comes to things like creativity, emotions, suffering, experiences and things. Yeah, exactly. AI can't feel at the end of the day, so it can't have emotions and feelings and it can't suffer in that way, so it doesn't understand what it's actually writing. And I think that's a very understandable problem that we would have, particularly with literature, the art world, songwriting, things like that. The things that go into those things are inherently human and you have to be careful about not bringing the robots into that space. Yeah. And listen, I'd say Nick Cave would say, if anyone's going to be churning out music that sounds like Nick Cave music, it's going to be me, Nick Cave. Jenny, it's fascinating and no doubt we'd be talking about it again and again over the next while. Jenny Darmondy of Silicon Republic. Thank you very much. We'll take a break. Email Brendan at RTE. Ie.